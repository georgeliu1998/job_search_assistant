# Base configuration for Job Search Assistant
# This file contains all default values and the complete configuration structure
# Environment-specific files (dev.toml, test.toml) override these defaults

[app]
name = "job-search-assistant"
version = "0.1.0"
debug = false

[logging]
level = "INFO"
format = "%(asctime)s %(name)s [%(levelname)s] %(message)s"

# Agent task to LLM profile mappings
[agents]
job_evaluation_extraction = "anthropic_default"
job_evaluation_reasoning = "anthropic_default"

# Business logic parameters for job evaluation
[evaluation_criteria]
min_salary = 160000
remote_required = true
ic_title_requirements = ["lead", "staff", "principal", "senior staff"]

# Reusable LLM configurations
[llm_profiles.anthropic_default]
provider = "anthropic"
model = "claude-3-5-haiku-20241022"
temperature = 0.0
max_tokens = 512

[llm_profiles.anthropic_reasoning]
provider = "anthropic"
model = "claude-sonnet-4-20250514"
temperature = 0.1
max_tokens = 1024

[llm_profiles.fireworks_fast]
provider = "fireworks"
model = "accounts/fireworks/models/llama-v3p1-8b-instruct"
temperature = 0.1
max_tokens = 512

# Observability and monitoring settings
[observability.langfuse]
enabled = false
host = "https://us.cloud.langfuse.com"
# public_key and secret_key loaded from environment variables 